{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSteps to create Word2Vec :\\n1)Tokenization of sentences\\n2)Create Histogram(optional)\\n3)Take most frequent words\\n4)Create a matrix with all the unique-words .It also represent the occurences relation between the words\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Steps to create Word2Vec :\n",
    "1)Tokenization of sentences\n",
    "2)Create Histogram(optional)\n",
    "3)Take most frequent words\n",
    "4)Create a matrix with all the unique-words .It also represent the occurences relation between the words\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk \n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"Mary had a little lamb,\n",
    "His fleece was white as snow,\n",
    "And everywhere that Mary went,\n",
    "The lamb was sure to go.\n",
    "\"Why does the lamb love Mary so?\"\n",
    "The eager children cry.\n",
    "\"Why, Mary loves the lamb, you know.\"\n",
    "The teacher did reply.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(r'[\\[0-9]*\\]',' ',paragraph)\n",
    "text = re.sub(r'\\s+','',text)\n",
    "text = text.lower()\n",
    "text = re.sub(r'\\d','',text)\n",
    "text = re.sub(r'\\st','',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['mary', 'had', 'a', 'little', 'lamb', ','],\n",
       " ['his', 'fleece', 'was', 'white', 'as', 'snow', ','],\n",
       " ['and', 'everywhere', 'that', 'mary', 'went', ','],\n",
       " ['the', 'lamb', 'was', 'sure', 'to', 'go', '.'],\n",
       " ['``', 'why', 'does', 'the', 'lamb', 'love', 'mary', 'so', '?', \"''\"],\n",
       " ['the', 'eager', 'children', 'cry', '.'],\n",
       " ['``',\n",
       "  'why',\n",
       "  ',',\n",
       "  'mary',\n",
       "  'loves',\n",
       "  'the',\n",
       "  'lamb',\n",
       "  ',',\n",
       "  'you',\n",
       "  'know',\n",
       "  '.',\n",
       "  \"''\"],\n",
       " ['the', 'teacher', 'did', 'reply', '.']]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [nltk.word_tokenize(s) for s in paragraph.lower().split('\\n')]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=37, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model = Word2Vec(sentences, min_count=1)\n",
    "\n",
    "# summarize the loaded model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mary', 'had', 'a', 'little', 'lamb', ',', 'his', 'fleece', 'was', 'white', 'as', 'snow', 'and', 'everywhere', 'that', 'went', 'the', 'sure', 'to', 'go', '.', '``', 'why', 'does', 'love', 'so', '?', \"''\", 'eager', 'children', 'cry', 'loves', 'you', 'know', 'teacher', 'did', 'reply']\n"
     ]
    }
   ],
   "source": [
    "# summarize vocabulary\n",
    "words = list(model.wv.vocab)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.6989446e-03  2.5972899e-03 -4.2116283e-03 -1.1127472e-03\n",
      " -4.1020880e-03  2.7017440e-03  1.4120834e-03  5.8861311e-05\n",
      " -1.5626701e-03  1.4902197e-04  3.5162794e-03  2.5035120e-03\n",
      " -2.8250592e-03  2.5700636e-03  3.1646090e-03 -2.2677751e-04\n",
      "  4.7157560e-03 -4.1587604e-04 -1.2905011e-03  3.4237392e-03\n",
      "  2.7466188e-03 -2.5712447e-03  3.3951418e-03  3.3018254e-03\n",
      "  1.8335328e-03 -4.7066612e-03 -1.6127849e-03  5.1271613e-04\n",
      " -4.1881902e-03  2.1930137e-03 -1.0835660e-03 -1.2058197e-03\n",
      " -1.0781900e-03  2.6562156e-03 -8.7869010e-04 -1.5410745e-03\n",
      " -2.2638374e-04 -2.0601901e-03 -2.7445152e-03 -2.6232547e-03\n",
      " -9.0227241e-04 -1.5816229e-03 -1.0901462e-04 -7.8982784e-04\n",
      " -1.7852950e-03  6.1472273e-04 -1.0768801e-03 -4.3090382e-03\n",
      " -8.2531222e-04 -1.0429870e-03 -2.4107436e-03 -1.5195018e-04\n",
      " -2.0364716e-03 -2.5677015e-03 -4.3870471e-03 -4.7557424e-03\n",
      " -3.9643706e-03  1.5427626e-05  7.9355123e-05 -3.0331661e-03\n",
      "  3.4549583e-03  3.1378756e-03  3.6078056e-03 -2.6882202e-03\n",
      "  4.4298680e-03  1.7251784e-03  7.8291690e-05  3.8494001e-04\n",
      " -1.2798060e-03  2.1460044e-04  4.6239989e-03 -2.8705276e-03\n",
      " -3.7217806e-03  2.9565834e-03 -1.0540688e-03 -4.0953765e-03\n",
      " -4.6652486e-03 -1.4065979e-03  2.6631525e-03  7.8264799e-04\n",
      "  8.2590581e-05  3.3926321e-03 -1.7101816e-03 -3.8305589e-03\n",
      "  2.3989968e-03 -3.9945128e-03 -3.3403933e-04 -4.1984380e-03\n",
      " -6.1583717e-04  1.1779810e-04 -2.6991772e-03  4.9227602e-03\n",
      "  4.3519106e-04  4.4948603e-03  2.6084762e-03  3.4303302e-03\n",
      " -4.9192030e-03 -4.6332856e-03  4.5383130e-03  1.1337228e-03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# access vector for one word\n",
    "#print(model['sentence'])\n",
    "print(model['lamb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=37, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "#trainign word vector\n",
    "model = Word2Vec(sentences,min_count = 1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mary', 'had', 'a', 'little', 'lamb', ',', 'his', 'fleece', 'was', 'white', 'as', 'snow', 'and', 'everywhere', 'that', 'went', 'the', 'sure', 'to', 'go', '.', '``', 'why', 'does', 'love', 'so', '?', \"''\", 'eager', 'children', 'cry', 'loves', 'you', 'know', 'teacher', 'did', 'reply']\n"
     ]
    }
   ],
   "source": [
    "words = list(model.wv.vocab)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.6989446e-03  2.5972899e-03 -4.2116283e-03 -1.1127472e-03\n",
      " -4.1020880e-03  2.7017440e-03  1.4120834e-03  5.8861311e-05\n",
      " -1.5626701e-03  1.4902197e-04  3.5162794e-03  2.5035120e-03\n",
      " -2.8250592e-03  2.5700636e-03  3.1646090e-03 -2.2677751e-04\n",
      "  4.7157560e-03 -4.1587604e-04 -1.2905011e-03  3.4237392e-03\n",
      "  2.7466188e-03 -2.5712447e-03  3.3951418e-03  3.3018254e-03\n",
      "  1.8335328e-03 -4.7066612e-03 -1.6127849e-03  5.1271613e-04\n",
      " -4.1881902e-03  2.1930137e-03 -1.0835660e-03 -1.2058197e-03\n",
      " -1.0781900e-03  2.6562156e-03 -8.7869010e-04 -1.5410745e-03\n",
      " -2.2638374e-04 -2.0601901e-03 -2.7445152e-03 -2.6232547e-03\n",
      " -9.0227241e-04 -1.5816229e-03 -1.0901462e-04 -7.8982784e-04\n",
      " -1.7852950e-03  6.1472273e-04 -1.0768801e-03 -4.3090382e-03\n",
      " -8.2531222e-04 -1.0429870e-03 -2.4107436e-03 -1.5195018e-04\n",
      " -2.0364716e-03 -2.5677015e-03 -4.3870471e-03 -4.7557424e-03\n",
      " -3.9643706e-03  1.5427626e-05  7.9355123e-05 -3.0331661e-03\n",
      "  3.4549583e-03  3.1378756e-03  3.6078056e-03 -2.6882202e-03\n",
      "  4.4298680e-03  1.7251784e-03  7.8291690e-05  3.8494001e-04\n",
      " -1.2798060e-03  2.1460044e-04  4.6239989e-03 -2.8705276e-03\n",
      " -3.7217806e-03  2.9565834e-03 -1.0540688e-03 -4.0953765e-03\n",
      " -4.6652486e-03 -1.4065979e-03  2.6631525e-03  7.8264799e-04\n",
      "  8.2590581e-05  3.3926321e-03 -1.7101816e-03 -3.8305589e-03\n",
      "  2.3989968e-03 -3.9945128e-03 -3.3403933e-04 -4.1984380e-03\n",
      " -6.1583717e-04  1.1779810e-04 -2.6991772e-03  4.9227602e-03\n",
      "  4.3519106e-04  4.4948603e-03  2.6084762e-03  3.4303302e-03\n",
      " -4.9192030e-03 -4.6332856e-03  4.5383130e-03  1.1337228e-03]\n"
     ]
    }
   ],
   "source": [
    "#finding word vector\n",
    "vector = model.wv['lamb']\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('?', 0.19955509901046753), ('eager', 0.18157094717025757), ('snow', 0.15329551696777344), ('why', 0.1528339982032776), (\"''\", 0.13123014569282532), ('go', 0.11739647388458252), ('so', 0.1026269793510437), ('little', 0.09650082886219025), ('you', 0.0947703868150711), ('did', 0.08000729978084564)]\n"
     ]
    }
   ],
   "source": [
    "similar  = model.wv.most_similar('lamb')\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
